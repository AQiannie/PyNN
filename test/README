PyNN testing is divided into several different types of test:
    * checking the API is syntactically consistent between different backends
    * unit tests
    * regression tests
    * system tests
    * running the example scripts
    * doctests    


API syntax consistency
----------------------

checkAPI.py


Unit tests
----------

In the `unittests` subdirectory. Tests can be run individually, or all at once
with coverage measurement using `alltests.sh`.

Note that the `generictests.py` script takes the simulator backend as a
command-line argument.

`generictests.py` should be run both with "python" and with "mpirun python".


Regression tests
----------------

Any time there is a bug/defect on the tracker, a script should be added to the
`regression` subdirectory, so we can check that the problem does not re-occur
in the future.


System tests
------------

These tests compare the output of different simulators for the same script. Each
test can be run directly by providing a parameter file on the command line,
e.g.:

python test_synaptic_integration.py parameters/test_synaptic_integration.param neuron nest

or it can be run with many different parameter sets using the explore_space.py
script, e.g.:

python explore_space.py -n 5 -f ~/mpd.hosts test_synaptic_integration.py parameters/test_synaptic_integration.space neuron nest




Running the example scripts
---------------------------

test_examples.py
test_examples_mpi.py


Documentation tests
-------------------

Tests that the code examples given in the documentation are correct.
XXXX